import gymnasium as gym
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim

# RND ä½¿ç”¨çš„å°å‹ CNN (é€‚é… MiniGrid 7x7x3)
class RNDNetwork(nn.Module):
    def __init__(self, input_shape, output_dim=128):
        super().__init__()
        n_input_channels = input_shape[0] # Usually 3
        
        self.cnn = nn.Sequential(
            nn.Conv2d(n_input_channels, 16, (2, 2)),
            nn.ReLU(),
            nn.Conv2d(16, 32, (2, 2)),
            nn.ReLU(),
            nn.Flatten()
        )
        
        # è®¡ç®— Flatten åçš„ç»´åº¦
        with torch.no_grad():
            dummy_input = torch.zeros(1, *input_shape)
            n_flatten = self.cnn(dummy_input).shape[1]
            
        self.linear = nn.Sequential(
            nn.Linear(n_flatten, 64),
            nn.ReLU(),
            nn.Linear(64, output_dim)
        )

    def forward(self, x):
        return self.linear(self.cnn(x))

class RNDWrapper(gym.Wrapper):
    def __init__(self, env, learning_rate=1e-4, intrinsic_weight=0.01, output_dim=128):
        super().__init__(env)
        self.intrinsic_weight = intrinsic_weight
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # è·å–è§‚æµ‹å½¢çŠ¶ (C, H, W)
        # æ³¨æ„: ImgObsWrapper è¾“å‡ºé€šå¸¸æ˜¯ (7, 7, 3), ä¹Ÿå°±æ˜¯ (H, W, C)
        # æˆ‘ä»¬éœ€è¦åœ¨ forward æ—¶è½¬ç½®ä¸º (C, H, W) ä»¥é€‚é… PyTorch
        self.obs_shape = (3, 7, 7) 
        
        # 1. Target Network (å›ºå®šï¼Œä¸è®­ç»ƒ)
        self.target_net = RNDNetwork(self.obs_shape, output_dim).to(self.device)
        for param in self.target_net.parameters():
            param.requires_grad = False
            
        # 2. Predictor Network (è®­ç»ƒ)
        self.predictor_net = RNDNetwork(self.obs_shape, output_dim).to(self.device)
        self.optimizer = optim.Adam(self.predictor_net.parameters(), lr=learning_rate)
        
    def _get_obs_tensor(self, obs):
        # å°† numpy (H, W, C) -> tensor (1, C, H, W)
        obs = torch.tensor(obs, dtype=torch.float32).to(self.device)
        obs = obs.permute(2, 0, 1).unsqueeze(0) # (H, W, C) -> (C, H, W) -> (1, C, H, W)
        return obs

    def step(self, action):
        obs, reward, terminated, truncated, info = self.env.step(action)
        
        # --- RND æ ¸å¿ƒé€»è¾‘ ---
        obs_tensor = self._get_obs_tensor(obs)
        
        with torch.no_grad():
            target_feature = self.target_net(obs_tensor)
            
        # å‰å‘ä¼ æ’­é¢„æµ‹
        predictor_feature = self.predictor_net(obs_tensor)
        
        # è®¡ç®—å†…åœ¨å¥–åŠ± (MSE Error)
        loss = nn.MSELoss()(predictor_feature, target_feature)
        intrinsic_reward = loss.item()
        
        # è®­ç»ƒ Predictor (åœ¨çº¿æ›´æ–°ï¼Œæ¯æ­¥éƒ½æ›´)
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
        # ç»„åˆå¥–åŠ±
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åªç¼©æ”¾ intrinsic rewardï¼Œå¹¶åŠ åˆ°åŸå§‹å¥–åŠ±ä¸Š
        total_reward = reward + self.intrinsic_weight * intrinsic_reward
        
        # åœ¨ info ä¸­è®°å½•å†…åœ¨å¥–åŠ±ï¼Œæ–¹ä¾¿è°ƒè¯•
        info['rnd_reward'] = intrinsic_reward
        
        return obs, total_reward, terminated, truncated, info


import gymnasium as gym
import matplotlib.pyplot as plt
import numpy as np
from minigrid.wrappers import ImgObsWrapper
from rnd_wrapper import RNDWrapper

def verify_rnd_logic():
    print("ğŸ” æ­£åœ¨éªŒè¯ RND é€»è¾‘ (Curiosity Check)...")
    
    # åˆå§‹åŒ–ç¯å¢ƒ
    env = gym.make("MiniGrid-Empty-8x8-v0", render_mode="rgb_array")
    env = ImgObsWrapper(env)
    # æƒé‡è®¾å¤§ä¸€ç‚¹ä»¥ä¾¿è§‚å¯Ÿ
    env = RNDWrapper(env, learning_rate=0.001, intrinsic_weight=1.0) 
    
    obs, _ = env.reset(seed=42)
    
    intrinsic_rewards = []
    
    # é˜¶æ®µ 1: å‘†åœ¨åŸåœ°ä¸åŠ¨ (Same State) 100æ¬¡
    # æˆ‘ä»¬ä¸æ‰§è¡Œ env.stepï¼Œè€Œæ˜¯æ‰‹åŠ¨å–‚åŒä¸€ä¸ª observation ç»™ wrapper çš„ç½‘ç»œ
    print("   é˜¶æ®µ 1: è¿ç»­è§‚å¯ŸåŒä¸€ä¸ªçŠ¶æ€ 100 æ¬¡ (é¢„æœŸï¼šå¥–åŠ±ä¸‹é™)")
    
    obs_tensor = env._get_obs_tensor(obs)
    target_feat = env.target_net(obs_tensor) # Target å›ºå®š
    
    for i in range(100):
        # æ‰‹åŠ¨è®­ç»ƒå¾ªç¯
        pred_feat = env.predictor_net(obs_tensor)
        loss = env.predictor_net.parameters()
        
        # è®¡ç®—å½“å‰ loss (reward)
        import torch.nn as nn
        loss_val = nn.MSELoss()(pred_feat, target_feat)
        intrinsic_rewards.append(loss_val.item())
        
        # æ›´æ–°ç½‘ç»œ
        env.optimizer.zero_grad()
        loss_val.backward()
        env.optimizer.step()

    # é˜¶æ®µ 2: çªç„¶æ¢ä¸€ä¸ªå®Œå…¨ä¸åŒçš„çŠ¶æ€ (New State)
    print("   é˜¶æ®µ 2: çªç„¶è§‚æµ‹æ–°çŠ¶æ€ (é¢„æœŸï¼šå¥–åŠ±æš´æ¶¨)")
    
    # æ¨¡æ‹Ÿä¸€ä¸ªå…¨é»‘æˆ–å…¨ç™½çš„æ–°çŠ¶æ€ (å™ªéŸ³)
    # æ³¨æ„ MiniGrid è§‚æµ‹èŒƒå›´æ˜¯ 0-255ï¼Œå½’ä¸€åŒ–é€šå¸¸åœ¨å†…éƒ¨å¤„ç†ï¼Œè¿™é‡Œç›´æ¥æ¨¡æ‹Ÿæ•°å€¼å˜åŒ–
    fake_obs = np.random.randint(0, 255, (7, 7, 3), dtype=np.uint8) 
    fake_tensor = env._get_obs_tensor(fake_obs)
    
    with torch.no_grad():
        t_feat = env.target_net(fake_tensor)
        p_feat = env.predictor_net(fake_tensor)
        new_reward = nn.MSELoss()(p_feat, t_feat).item()
        
    intrinsic_rewards.append(new_reward)
    
    # ç»˜å›¾
    plt.figure(figsize=(8, 4))
    plt.plot(intrinsic_rewards, marker='o')
    plt.axvline(x=99, color='r', linestyle='--', label="Switch State")
    plt.title("RND Intrinsic Reward Verification")
    plt.xlabel("Training Steps (on same state -> new state)")
    plt.ylabel("Intrinsic Reward (MSE Loss)")
    plt.legend()
    plt.grid(True)
    plt.savefig("verification_rnd.png")
    print("âœ… éªŒè¯å®Œæˆï¼è¯·æŸ¥çœ‹ verification_rnd.png")
    print(f"   åˆå§‹å¥–åŠ±: {intrinsic_rewards[0]:.4f}")
    print(f"   ç¬¬100æ¬¡å¥–åŠ±: {intrinsic_rewards[99]:.4f} (åº”æ˜¾è‘—é™ä½)")
    print(f"   æ–°çŠ¶æ€å¥–åŠ±: {intrinsic_rewards[100]:.4f} (åº”æ˜¾è‘—å‡é«˜)")

if __name__ == "__main__":
    verify_rnd_logic()